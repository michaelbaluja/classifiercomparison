{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install statements for all utilized libraries (uncomment which are needed)\n",
    "#!pip3 install pandas # installs numpy with it \n",
    "#!pip3 install numpy\n",
    "#!pip3 install pickle\n",
    "#!pip3 install sklearn\n",
    "#!pip3 install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Misc\n",
    "import pickle # saving/loading metrics\n",
    "\n",
    "# ML\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Text Processing\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dict(dictionary, filename, verbose=False):\n",
    "    '''\n",
    "    Saves dictionary object as a pickle file for reloading and easy viewing\n",
    "    \n",
    "    Args:\n",
    "    - dictionary (dict): data to be saved\n",
    "    - filename (str): filename for dictionary to be stored in\n",
    "    - verbose=False (bool): sepcifies if exact filename should be used. if False, .json extension appended to filename if not already present\n",
    "    Return:\n",
    "    - filename (str): filename for dictionary to be stored in\n",
    "    '''\n",
    "    if (not verbose) and ('.pickle' not in filename):\n",
    "        filename += '.pickle'\n",
    "        \n",
    "    with open(filename, \"wb\") as outfile:  \n",
    "        pickle.dump(dictionary, outfile)\n",
    "        outfile.close()\n",
    "    \n",
    "    return filename\n",
    "        \n",
    "def load_dict(filename, verbose=False):\n",
    "    '''\n",
    "    Loads dictionary of metrics from given filename\n",
    "    \n",
    "    Args:\n",
    "    - filename (str): file to load\n",
    "    - verbose=False (bool): sepcifies if exact filename should be used. if False, .pickle extension appended to filename if not already present\n",
    "    Return\n",
    "    - dictionary (dict): data found in file\n",
    "    - None (None): return None val in case exception is raised and dictionary file does not exist\n",
    "    '''\n",
    "    if (not verbose) and ('.pickle' not in filename):\n",
    "        filename += '.pickle'\n",
    "\n",
    "    try:\n",
    "        with open(filename, 'rb') as pickle_file: \n",
    "            dictionary = pickle.load(pickle_file) \n",
    "    except FileNotFoundError as e:\n",
    "        print(e)\n",
    "        return None\n",
    "    \n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dict to store {name: dataset}\n",
    "dataset_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vectorizer that turns text samples into token vector \n",
    "vectorizer = CountVectorizer(analyzer='word', tokenizer=word_tokenize, stop_words=stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yelp Polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/.local/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'might', 'must', \"n't\", 'need', 'sha', 'wo', 'would'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "# Create vectorizer that turns text samples into token vector \n",
    "yelp_vectorizer = CountVectorizer(analyzer='word', tokenizer=word_tokenize, stop_words=stopwords.words('english'), max_features=6000)\n",
    "\n",
    "# Load yelp data sets\n",
    "yelp_test_df = pd.read_csv('../data/yelp_review_polarity_csv/test.csv', names=['label', 'data']) \n",
    "yelp_train_df = pd.read_csv('../data/yelp_review_polarity_csv/train.csv', names=['label', 'data']) \n",
    "\n",
    "# Since yelp data set is already split into test and train, recombine\n",
    "yelp_df = pd.concat([yelp_test_df, yelp_train_df])\n",
    "\n",
    "# Data set is too large to work with in memory since I don't have 2TiB of RAM just lying around, so we're cutting the data down\n",
    "yelp_df = yelp_df.sample(n=16000,replace=False,axis='index')\n",
    "\n",
    "# Change 1, 2 label to 0, 1 for uniformity with other data sets\n",
    "# Data set has 1 for negative and 2 for positive, so we switch 0 to negative and 1 to positive\n",
    "yelp_df['label'] = yelp_df['label'].apply(lambda label: 0 if label == 1 else 1)\n",
    "\n",
    "#Vectorize\n",
    "yelp_df['data'] = vectorizer.fit_transform(yelp_df['data']).toarray()\n",
    "\n",
    "# Transform df to np array for easier use & add info to dict\n",
    "yelp_data = yelp_df.values\n",
    "dataset_dict['yelp'] = yelp_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subjectivity/Objectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vectorizer that turns text samples into token vector \n",
    "subob_vectorizer = CountVectorizer(analyzer='word', tokenizer=word_tokenize, stop_words=stopwords.words('english'), max_features=2200)\n",
    "\n",
    "# Load data sets\n",
    "subjectivity_df = pd.read_csv('../data/subjectobject/subjectivity.txt', sep='\\n', encoding='latin-1', names=['data'])\n",
    "objectivity_df = pd.read_csv('../data/subjectobject/objectivity.txt', sep='\\n', encoding='latin-1', names=['data'])\n",
    "\n",
    "# Add labels (subjective is 0, objective is 0)\n",
    "subjectivity_df['label'] = 0\n",
    "objectivity_df['label'] = 1\n",
    "\n",
    "# Combine data sets and rearrange columns for uniformity\n",
    "sub_ob_df = pd.concat([subjectivity_df, objectivity_df])\n",
    "sub_ob_df = sub_ob_df.reindex(columns=['label', 'data'])\n",
    "\n",
    "#Vectorize\n",
    "sub_ob_df['data'] = vectorizer.fit_transform(sub_ob_df['data']).toarray()\n",
    "\n",
    "#Transform df to np array, and add to dict\n",
    "sub_ob_data = sub_ob_df.values\n",
    "dataset_dict['sub_ob'] = sub_ob_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clickbait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vectorizer that turns text samples into token vector \n",
    "clickbait_vectorizer = CountVectorizer(analyzer='word', tokenizer=word_tokenize, stop_words=stopwords.words('english'), max_features=2500)\n",
    "\n",
    "# Load data sets\n",
    "clickbait_df = pd.read_csv('../data/clickbait/clickbait_data', sep='\\n', names=['data'])\n",
    "nonclickbait_df = pd.read_csv('../data/clickbait/non_clickbait_data', sep='\\n', names=['data'])\n",
    "\n",
    "# Add labels (subjective is 0, objective is 0)\n",
    "nonclickbait_df['label'] = 0\n",
    "clickbait_df['label'] = 1\n",
    "\n",
    "# Combine data sets and rearrange columns for uniformity\n",
    "clickbait_df = pd.concat([clickbait_df, nonclickbait_df])\n",
    "clickbait_df = clickbait_df.reindex(columns=['label', 'data'])\n",
    "\n",
    "#Vectorize\n",
    "clickbait_df['data'] = vectorizer.fit_transform(clickbait_df['data']).toarray()\n",
    "\n",
    "#Transform df to np array, and add to dict\n",
    "clickbait_data = clickbait_df.values\n",
    "dataset_dict['clickbait'] = clickbait_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create metric dict\n",
    "svm_metric_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid of parameters to search over for SVM\n",
    "c_vals = [1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3]\n",
    "param_grid_svm = [{'kernel': ['linear'], 'C': c_vals}, {'kernel': ['poly'], 'degree': [2,3], 'C': c_vals}, {'kernel': ['rbf'], 'gamma': [0, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 2], 'C': c_vals}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model & grid search object\n",
    "svc = SVC()\n",
    "clf_svc = GridSearchCV(estimator=svc, param_grid=param_grid_svm, cv=5, n_jobs=3, verbose=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 132 candidates, totalling 660 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   2 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=3)]: Done   7 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=3)]: Done  12 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=3)]: Done  19 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=3)]: Done  26 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=3)]: Done  35 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=3)]: Done  55 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=3)]: Done  66 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=3)]: Done  79 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=3)]: Done  92 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=3)]: Done 107 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=3)]: Done 122 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=3)]: Done 139 tasks      | elapsed:   13.7s\n",
      "[Parallel(n_jobs=3)]: Done 156 tasks      | elapsed:   15.4s\n",
      "[Parallel(n_jobs=3)]: Done 175 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:   20.1s\n",
      "[Parallel(n_jobs=3)]: Done 215 tasks      | elapsed:   22.5s\n",
      "[Parallel(n_jobs=3)]: Done 236 tasks      | elapsed:   25.0s\n",
      "[Parallel(n_jobs=3)]: Done 259 tasks      | elapsed:   27.7s\n",
      "[Parallel(n_jobs=3)]: Done 282 tasks      | elapsed:   30.3s\n",
      "[Parallel(n_jobs=3)]: Done 307 tasks      | elapsed:   33.3s\n",
      "[Parallel(n_jobs=3)]: Done 332 tasks      | elapsed:   36.4s\n",
      "[Parallel(n_jobs=3)]: Done 359 tasks      | elapsed:   39.6s\n",
      "[Parallel(n_jobs=3)]: Done 386 tasks      | elapsed:   42.8s\n",
      "[Parallel(n_jobs=3)]: Done 415 tasks      | elapsed:   46.2s\n",
      "[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:   49.5s\n",
      "[Parallel(n_jobs=3)]: Done 475 tasks      | elapsed:   53.2s\n",
      "[Parallel(n_jobs=3)]: Done 506 tasks      | elapsed:   56.9s\n",
      "[Parallel(n_jobs=3)]: Done 539 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=3)]: Done 572 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 607 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 642 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 660 out of 660 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 132 candidates, totalling 660 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   2 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=3)]: Done   7 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=3)]: Done  12 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=3)]: Done  19 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=3)]: Done  26 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=3)]: Done  35 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=3)]: Done  55 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=3)]: Done  66 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=3)]: Done  79 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=3)]: Done  92 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=3)]: Done 107 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=3)]: Done 122 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=3)]: Done 139 tasks      | elapsed:   12.8s\n",
      "[Parallel(n_jobs=3)]: Done 156 tasks      | elapsed:   14.4s\n",
      "[Parallel(n_jobs=3)]: Done 175 tasks      | elapsed:   16.6s\n",
      "[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:   18.8s\n",
      "[Parallel(n_jobs=3)]: Done 215 tasks      | elapsed:   21.3s\n",
      "[Parallel(n_jobs=3)]: Done 236 tasks      | elapsed:   23.8s\n",
      "[Parallel(n_jobs=3)]: Done 259 tasks      | elapsed:   26.4s\n",
      "[Parallel(n_jobs=3)]: Done 282 tasks      | elapsed:   29.0s\n",
      "[Parallel(n_jobs=3)]: Done 307 tasks      | elapsed:   32.0s\n",
      "[Parallel(n_jobs=3)]: Done 332 tasks      | elapsed:   35.1s\n",
      "[Parallel(n_jobs=3)]: Done 359 tasks      | elapsed:   38.3s\n",
      "[Parallel(n_jobs=3)]: Done 386 tasks      | elapsed:   41.5s\n",
      "[Parallel(n_jobs=3)]: Done 415 tasks      | elapsed:   44.7s\n",
      "[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:   48.2s\n",
      "[Parallel(n_jobs=3)]: Done 475 tasks      | elapsed:   51.8s\n",
      "[Parallel(n_jobs=3)]: Done 506 tasks      | elapsed:   55.6s\n",
      "[Parallel(n_jobs=3)]: Done 539 tasks      | elapsed:   59.4s\n",
      "[Parallel(n_jobs=3)]: Done 572 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 607 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 642 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 660 out of 660 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 132 candidates, totalling 660 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   2 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=3)]: Done   7 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=3)]: Done  12 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=3)]: Done  19 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=3)]: Done  26 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=3)]: Done  35 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=3)]: Done  55 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=3)]: Done  66 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=3)]: Done  79 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=3)]: Done  92 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=3)]: Done 107 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=3)]: Done 122 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=3)]: Done 139 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=3)]: Done 156 tasks      | elapsed:   14.4s\n",
      "[Parallel(n_jobs=3)]: Done 175 tasks      | elapsed:   16.5s\n",
      "[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:   18.7s\n",
      "[Parallel(n_jobs=3)]: Done 215 tasks      | elapsed:   21.1s\n",
      "[Parallel(n_jobs=3)]: Done 236 tasks      | elapsed:   23.6s\n",
      "[Parallel(n_jobs=3)]: Done 259 tasks      | elapsed:   26.2s\n",
      "[Parallel(n_jobs=3)]: Done 282 tasks      | elapsed:   28.8s\n",
      "[Parallel(n_jobs=3)]: Done 307 tasks      | elapsed:   31.7s\n",
      "[Parallel(n_jobs=3)]: Done 332 tasks      | elapsed:   34.6s\n",
      "[Parallel(n_jobs=3)]: Done 359 tasks      | elapsed:   37.7s\n",
      "[Parallel(n_jobs=3)]: Done 386 tasks      | elapsed:   40.8s\n",
      "[Parallel(n_jobs=3)]: Done 415 tasks      | elapsed:   44.2s\n",
      "[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:   47.5s\n",
      "[Parallel(n_jobs=3)]: Done 475 tasks      | elapsed:   51.1s\n",
      "[Parallel(n_jobs=3)]: Done 506 tasks      | elapsed:   54.7s\n",
      "[Parallel(n_jobs=3)]: Done 539 tasks      | elapsed:   58.5s\n",
      "[Parallel(n_jobs=3)]: Done 572 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=3)]: Done 607 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 642 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 660 out of 660 | elapsed:  1.2min finished\n",
      "/home/michael/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/michael/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for name, dataset in dataset_dict.items():\n",
    "    # Get data\n",
    "    X, y = dataset[:, 1:], dataset[:, :1] #Treats first column as label\n",
    "    for i in range(3):\n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=5000, shuffle=True)\n",
    "        \n",
    "        clf_svc.fit(X_train, y_train.ravel()) # Fit training data to model\n",
    "        \n",
    "        # Train set performance\n",
    "        y_train_pred = clf_svc.predict(X_train)\n",
    "        acc_train = accuracy_score(y_train, y_train_pred)\n",
    "        precision_train, recall_train, f1_train, _ = precision_recall_fscore_support(y_train, y_train_pred)\n",
    "        \n",
    "        # Test set performance\n",
    "        y_test_pred = clf_svc.predict(X_test) # Predict test values using best parameters from classifier\n",
    "        acc_test = accuracy_score(y_test, y_test_pred) # Get accuracy for predictions\n",
    "        precision_test, recall_test, f1_test, _ = precision_recall_fscore_support(y_test, y_test_pred)\n",
    "        \n",
    "        svm_metric_dict[(name, i)] = {'acc_test': acc_test, 'acc_train': acc_train, 'precision_test': precision_test, 'precision_train': precision_train, 'recall_test': recall_test, 'recall_train': recall_train,\n",
    "                                      'f1_test': f1_test, 'f1_train': f1_train, 'model': clf_svc, 'cv_results': clf_svc.cv_results_} # Add metrics to dict for analysis\n",
    "        save_dict(svm_metric_dict, '../checkpoints/svm/svm_{}_{}.pickle'.format(name, i)) # Save checkpoint results in case of hardware failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "###### DEPRACATED FOR MULTITHREAD SKLEARN GRID SEARCH, KEPT IN CASE OF MEASURING OTHER METRICS\n",
    "from sklearn.model_selection import KFold, ParameterGrid\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Cycle across each param combo\n",
    "performance_dict = {}\n",
    "for param_dict in tqdm(list(ParameterGrid(param_grid))):\n",
    "    performance = 0\n",
    "    C, degree, gamma, kernel = param_dict.values()\n",
    "    if ((kernel in ('linear', 'rbf') and degree > 0) or  # Don't want to run linear or rbf with polynomial degrees (degree will be ignored but we'll get duplicate trials)\n",
    "        (kernel == 'poly' and degree == 0) or # Don't want polynomial with degree 0\n",
    "        (kernel in ('linear', 'poly') and gamma > 0) or # Don't want linear or poly with gamma param\n",
    "        (kernel == 'rbf' and gamma == 0)): # Don't want rbf with 0 gamma\n",
    "        continue\n",
    "    # Do k fold validation\n",
    "    for train, validate in kf.split(X_letter_train):\n",
    "        X_letter_train_cross, X_letter_val_cross, y_letter_train_cross, y_letter_val_cross = X_letter_train[train], X_letter_train[validate], y_letter_train[train], y_letter_train[validate] # get data folds\n",
    "        svm_letter = SVC(C=C, degree=degree, kernel=kernel) # create the model #NOTE: not scaling because all data appears to follow the same scaling regardless\n",
    "        svm_letter.fit(X_letter_train_cross, y_letter_train_cross.ravel()) # fit the model\n",
    "        y_letter_val_cross_pred = svm_letter.predict(X_letter_val_cross) # predict validation data\n",
    "        performance += accuracy_score(y_letter_val_cross, y_letter_val_cross_pred) # keep track of performance\n",
    "    # Average the performance\n",
    "    performance /= 5\n",
    "    \n",
    "    # Add performance info to dict\n",
    "    performance_dict[(C, degree, kernel)] = performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_metric_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_logreg = [{'penalty': ['l2'], 'C': [1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3, 1e4]}, {'penalty': ['none']}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "clf_logreg = GridSearchCV(estimator=logreg, param_grid=param_grid_logreg, cv=5, n_jobs=3, verbose=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, dataset in dataset_dict.items():\n",
    "    X, y = dataset[:, 1:], dataset[:, :1]\n",
    "    for i in range(3):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=5000, shuffle=True)\n",
    "        \n",
    "        clf_logreg.fit(X_train, y_train.ravel())\n",
    "        \n",
    "        # Train set performance\n",
    "        y_train_pred = clf_logreg.predict(X_train)\n",
    "        acc_train = accuracy_score(y_train, y_train_pred)\n",
    "        precision_train, recall_train, f1_train, _ = precision_recall_fscore_support(y_train, y_train_pred)\n",
    "        \n",
    "        # Test set performance\n",
    "        y_test_pred = clf_logreg.predict(X_test) # Predict test values using best parameters from classifier\n",
    "        acc_test = accuracy_score(y_test, y_test_pred) # Get accuracy for predictions\n",
    "        precision_test, recall_test, f1_test, _ = precision_recall_fscore_support(y_test, y_test_pred)\n",
    "        \n",
    "        logreg_metric_dict[(name, i)] = {'acc_test': acc_test, 'acc_train': acc_train, 'precision_test': precision_test, 'precision_train': precision_train, 'recall_test': recall_test, 'recall_train': recall_train,\n",
    "                                      'f1_test': f1_test, 'f1_train': f1_train, 'model': clf_logreg, 'cv_results': clf_logreg.cv_results_} # Add metrics to dict for analysis\n",
    "        save_dict(logreg_metric_dict, '../checkpoints/logreg/logreg_{}_{}.pickle'.format(name, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('clickbait', 0): {'acc_test': 0.49974074074074076,\n",
       "  'acc_train': 0.506,\n",
       "  'precision_test': array([0.49938814, 0.78787879]),\n",
       "  'precision_train': array([0.50570571, 0.8       ]),\n",
       "  'recall_test': array([0.99948048, 0.00192222]),\n",
       "  'recall_train': array([0.99960427, 0.00161747]),\n",
       "  'f1_test': array([0.66600727, 0.00383509]),\n",
       "  'f1_train': array([0.67162989, 0.00322841]),\n",
       "  'model': GridSearchCV(cv=5, estimator=SVC(), n_jobs=3,\n",
       "               param_grid=[{'C': [1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1,\n",
       "                                  1.0, 10.0, 100.0, 1000.0],\n",
       "                            'kernel': ['linear']},\n",
       "                           {'C': [1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1,\n",
       "                                  1.0, 10.0, 100.0, 1000.0],\n",
       "                            'degree': [2, 3], 'kernel': ['poly']},\n",
       "                           {'C': [1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1,\n",
       "                                  1.0, 10.0, 100.0, 1000.0],\n",
       "                            'gamma': [0, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1,\n",
       "                                      2],\n",
       "                            'kernel': ['rbf']}],\n",
       "               scoring='accuracy', verbose=10),\n",
       "  'cv_results': {'mean_fit_time': array([0.20424261, 0.20237737, 0.20244756, 0.20917668, 0.20571856,\n",
       "          0.20292053, 0.20444803, 0.2030097 , 0.20982156, 0.20286231,\n",
       "          0.20422754, 0.26850314, 0.27023048, 0.28090286, 0.26830549,\n",
       "          0.26690497, 0.2656333 , 0.26402631, 0.26537099, 0.26450362,\n",
       "          0.26406527, 0.26427417, 0.26278782, 0.27144198, 0.27478566,\n",
       "          0.27079091, 0.26309299, 0.26365652, 0.26458011, 0.26501961,\n",
       "          0.2789228 , 0.27635078, 0.38641915, 0.2970953 , 0.29685125,\n",
       "          0.29778957, 0.29902587, 0.29728851, 0.29701715, 0.29665356,\n",
       "          0.29688764, 0.29755306, 0.29649038, 0.29660726, 0.29707942,\n",
       "          0.29680352, 0.29753699, 0.29733596, 0.29679856, 0.29758439,\n",
       "          0.29668002, 0.31173921, 0.29734626, 0.2971365 , 0.29755588,\n",
       "          0.2970799 , 0.29805603, 0.29863229, 0.29750681, 0.29777613,\n",
       "          0.29686875, 0.29764752, 0.2982224 , 0.30393114, 0.31285415,\n",
       "          0.31018195, 0.29797368, 0.29918041, 0.30361214, 0.30616074,\n",
       "          0.29941192, 0.29771476, 0.30079122, 0.3090486 , 0.30658088,\n",
       "          0.29602046, 0.29889207, 0.30448327, 0.30605183, 0.29990878,\n",
       "          0.30713105, 0.29715867, 0.29669452, 0.29623656, 0.2988874 ,\n",
       "          0.29794369, 0.29712048, 0.29751353, 0.29675174, 0.29671345,\n",
       "          0.29671941, 0.29840293, 0.2977406 , 0.2965445 , 0.29652328,\n",
       "          0.29712801, 0.29575605, 0.29597406, 0.29695473, 0.29771485,\n",
       "          0.29761386, 0.30046296, 0.30823808, 0.29679379, 0.29576483,\n",
       "          0.29516177, 0.29607038, 0.29610538, 0.29669967, 0.29603963,\n",
       "          0.29588008, 0.2975965 , 0.29892597, 0.29652686, 0.2952424 ,\n",
       "          0.29635115, 0.29637518, 0.29670248, 0.30225782, 0.30251937,\n",
       "          0.29673839, 0.29596806, 0.29591627, 0.29536924, 0.29585614,\n",
       "          0.29654546, 0.29614272, 0.29957376, 0.29558258, 0.29569063,\n",
       "          0.29581118, 0.29552174]),\n",
       "   'std_fit_time': array([0.00116355, 0.00064997, 0.00143136, 0.00744117, 0.00260634,\n",
       "          0.00211838, 0.00295027, 0.00106423, 0.00733818, 0.00076993,\n",
       "          0.00116843, 0.00202209, 0.00716025, 0.00805918, 0.00486679,\n",
       "          0.00220389, 0.0010794 , 0.00046914, 0.00274796, 0.00155131,\n",
       "          0.00111206, 0.00050065, 0.00079791, 0.00496967, 0.00304913,\n",
       "          0.00441571, 0.00060954, 0.00035393, 0.00131638, 0.00116109,\n",
       "          0.00896798, 0.00850843, 0.1011615 , 0.00264171, 0.00097688,\n",
       "          0.00121893, 0.00212414, 0.00053825, 0.00108062, 0.00078559,\n",
       "          0.00122361, 0.00165341, 0.00090851, 0.00044903, 0.00122692,\n",
       "          0.0013042 , 0.00146409, 0.00121227, 0.00116838, 0.00077257,\n",
       "          0.00082158, 0.01761265, 0.00044019, 0.00063401, 0.00095405,\n",
       "          0.0008671 , 0.00064604, 0.00237213, 0.00182983, 0.00053435,\n",
       "          0.00124465, 0.00113015, 0.00129379, 0.00645564, 0.00243377,\n",
       "          0.00461394, 0.00104192, 0.00239402, 0.00495697, 0.00545511,\n",
       "          0.00239645, 0.00243471, 0.00299636, 0.00487375, 0.00167944,\n",
       "          0.00064935, 0.00313793, 0.00649782, 0.00511094, 0.00330933,\n",
       "          0.01368572, 0.00117597, 0.00039192, 0.00026807, 0.00489465,\n",
       "          0.00274352, 0.00226571, 0.00088007, 0.00122891, 0.00103478,\n",
       "          0.00035419, 0.00273316, 0.00220741, 0.00100486, 0.00027847,\n",
       "          0.00055391, 0.00023543, 0.00028179, 0.00075457, 0.00052139,\n",
       "          0.00088708, 0.00380648, 0.01433034, 0.00091065, 0.00040214,\n",
       "          0.00032545, 0.00040468, 0.00052123, 0.00083415, 0.00076697,\n",
       "          0.00021101, 0.0039917 , 0.00643101, 0.00158027, 0.00050862,\n",
       "          0.00064967, 0.00114031, 0.00100169, 0.01124239, 0.01248392,\n",
       "          0.00138965, 0.0004597 , 0.00045647, 0.00035363, 0.00049674,\n",
       "          0.00099077, 0.00105901, 0.00124789, 0.00072602, 0.00034883,\n",
       "          0.00052114, 0.00034543]),\n",
       "   'mean_score_time': array([0.02323995, 0.02370539, 0.02429905, 0.02341208, 0.02267523,\n",
       "          0.02313681, 0.02393684, 0.02312684, 0.02276063, 0.02362022,\n",
       "          0.02326732, 0.03520079, 0.03593197, 0.03657031, 0.03542857,\n",
       "          0.03526311, 0.03659325, 0.03497076, 0.03511052, 0.0350667 ,\n",
       "          0.03544779, 0.03496881, 0.03584743, 0.03576856, 0.03600092,\n",
       "          0.03538628, 0.03565173, 0.03540998, 0.03502626, 0.03508563,\n",
       "          0.03611312, 0.03595953, 0.0356739 , 0.04598093, 0.04652801,\n",
       "          0.04669747, 0.04641013, 0.04624414, 0.04677138, 0.04618335,\n",
       "          0.04611397, 0.04613075, 0.04619188, 0.0465364 , 0.0460578 ,\n",
       "          0.0458652 , 0.04589777, 0.0460443 , 0.04587884, 0.04590192,\n",
       "          0.04648876, 0.04583359, 0.04595647, 0.04597368, 0.04606771,\n",
       "          0.04595923, 0.0460515 , 0.04624357, 0.04593701, 0.04598074,\n",
       "          0.0459074 , 0.04596548, 0.04621882, 0.04660954, 0.04724998,\n",
       "          0.04694977, 0.04633341, 0.04620886, 0.04639268, 0.04602885,\n",
       "          0.04606848, 0.04649763, 0.04667115, 0.0469986 , 0.04655848,\n",
       "          0.04591842, 0.04608727, 0.04743929, 0.04636903, 0.0460772 ,\n",
       "          0.04667163, 0.04600706, 0.04611773, 0.04608293, 0.04601903,\n",
       "          0.04597569, 0.04625254, 0.04617844, 0.04606166, 0.04599423,\n",
       "          0.04602475, 0.04617662, 0.04600577, 0.0461504 , 0.04607453,\n",
       "          0.04605927, 0.045927  , 0.04600544, 0.04667726, 0.0461513 ,\n",
       "          0.04659152, 0.04644928, 0.04858403, 0.04604135, 0.04601679,\n",
       "          0.04589868, 0.04601502, 0.04601488, 0.04615126, 0.04589505,\n",
       "          0.04605994, 0.04592266, 0.04590015, 0.04605765, 0.04585233,\n",
       "          0.04591708, 0.04594655, 0.04612603, 0.04858165, 0.04658561,\n",
       "          0.04586854, 0.04593205, 0.04587946, 0.04573522, 0.04595103,\n",
       "          0.04602952, 0.0458632 , 0.04762001, 0.0461484 , 0.04588141,\n",
       "          0.04604454, 0.04589567]),\n",
       "   'std_score_time': array([5.12078765e-04, 1.44985926e-03, 2.90631480e-03, 5.10801078e-04,\n",
       "          1.64080311e-04, 2.61276715e-04, 1.81010982e-03, 3.74676447e-04,\n",
       "          2.02563770e-04, 8.50171296e-04, 7.40612775e-04, 3.23259350e-04,\n",
       "          8.42730791e-04, 7.67843830e-04, 4.48355742e-04, 7.34267827e-04,\n",
       "          1.62091354e-03, 1.57095013e-04, 2.05777549e-04, 2.74095713e-04,\n",
       "          7.91335959e-04, 1.66216323e-04, 8.33443098e-04, 4.23086688e-04,\n",
       "          1.23007732e-03, 7.41324322e-04, 1.08861705e-03, 9.11146606e-04,\n",
       "          3.62080116e-04, 2.66456775e-04, 1.43973448e-03, 9.98154060e-04,\n",
       "          1.07822748e-03, 3.72041142e-04, 4.01144445e-04, 1.40789446e-03,\n",
       "          4.46238582e-04, 3.57986620e-04, 7.86945754e-04, 3.14476546e-04,\n",
       "          3.33096371e-04, 2.46072766e-04, 9.03472896e-04, 1.01832718e-03,\n",
       "          2.47913715e-04, 1.89080009e-04, 1.36703933e-04, 1.08928478e-04,\n",
       "          1.52655855e-04, 1.50387485e-04, 8.44936110e-04, 1.80993655e-04,\n",
       "          1.23952038e-04, 1.84341607e-04, 2.03204086e-04, 1.27553806e-04,\n",
       "          1.67381118e-04, 4.64678033e-04, 1.28711360e-04, 1.68226865e-04,\n",
       "          1.22537279e-04, 1.04079080e-04, 3.02096169e-04, 5.54148577e-04,\n",
       "          7.09216553e-04, 7.88466723e-04, 3.85190686e-04, 2.99718385e-04,\n",
       "          3.07039627e-04, 3.16893362e-04, 2.58409728e-04, 1.05075384e-03,\n",
       "          7.54998184e-04, 8.98900126e-04, 3.63214679e-04, 1.59767021e-04,\n",
       "          1.92017593e-04, 5.74463467e-04, 5.02713326e-04, 2.57713055e-04,\n",
       "          1.00905995e-03, 2.41352653e-04, 2.53784428e-04, 2.16744514e-04,\n",
       "          2.92978249e-04, 1.70019096e-04, 2.87419996e-04, 3.17257812e-04,\n",
       "          1.38747782e-04, 1.88624473e-04, 1.52801528e-04, 2.46463534e-04,\n",
       "          2.06459168e-04, 2.64671874e-04, 1.48206220e-04, 1.53214954e-04,\n",
       "          1.65167981e-04, 2.09671724e-04, 1.37281120e-03, 2.09535107e-04,\n",
       "          9.88507949e-04, 5.77083778e-04, 4.93200659e-03, 9.80408507e-05,\n",
       "          1.09082959e-04, 1.48506338e-04, 2.05383899e-04, 1.57743800e-04,\n",
       "          2.60015267e-04, 1.04133790e-04, 1.05838151e-04, 1.44493981e-04,\n",
       "          2.00992400e-04, 3.36482579e-04, 1.37044658e-04, 1.53343327e-04,\n",
       "          1.58248050e-04, 3.49152515e-04, 3.74649481e-03, 1.41366032e-03,\n",
       "          1.04449283e-04, 1.81865280e-04, 2.08982261e-04, 1.40242064e-04,\n",
       "          1.69403177e-04, 2.40480585e-04, 1.59334364e-04, 3.50747099e-03,\n",
       "          5.44691935e-04, 1.62448601e-04, 1.92304849e-04, 1.89014641e-04]),\n",
       "   'param_C': masked_array(data=[1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0,\n",
       "                      10.0, 100.0, 1000.0, 1e-07, 1e-07, 1e-06, 1e-06, 1e-05,\n",
       "                      1e-05, 0.0001, 0.0001, 0.001, 0.001, 0.01, 0.01, 0.1,\n",
       "                      0.1, 1.0, 1.0, 10.0, 10.0, 100.0, 100.0, 1000.0,\n",
       "                      1000.0, 1e-07, 1e-07, 1e-07, 1e-07, 1e-07, 1e-07,\n",
       "                      1e-07, 1e-07, 1e-07, 1e-06, 1e-06, 1e-06, 1e-06, 1e-06,\n",
       "                      1e-06, 1e-06, 1e-06, 1e-06, 1e-05, 1e-05, 1e-05, 1e-05,\n",
       "                      1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 0.0001, 0.0001,\n",
       "                      0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                      0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                      0.001, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                      0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 1.0,\n",
       "                      1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 10.0, 10.0,\n",
       "                      10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 100.0, 100.0,\n",
       "                      100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0,\n",
       "                      1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0,\n",
       "                      1000.0, 1000.0],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_kernel': masked_array(data=['linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                      'linear', 'linear', 'linear', 'linear', 'linear',\n",
       "                      'linear', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                      'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                      'poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                      'poly', 'poly', 'poly', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                      'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                      'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                      'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                      'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                      'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                      'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                      'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                      'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                      'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                      'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                      'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                      'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf'],\n",
       "                mask=[False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_degree': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, 2, 3, 2, 3,\n",
       "                      2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3,\n",
       "                      --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                      --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                      --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                      --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                      --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                      --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                      --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                      --],\n",
       "                mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                       True,  True,  True, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False,  True,  True,  True,  True,  True,  True,  True,\n",
       "                       True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                       True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                       True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                       True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                       True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                       True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                       True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                       True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                       True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                       True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                       True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                       True,  True,  True,  True],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'param_gamma': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                      --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
       "                      --, --, --, --, --, 0, 0.001, 0.005, 0.01, 0.05, 0.1,\n",
       "                      0.5, 1, 2, 0, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 2,\n",
       "                      0, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 2, 0, 0.001,\n",
       "                      0.005, 0.01, 0.05, 0.1, 0.5, 1, 2, 0, 0.001, 0.005,\n",
       "                      0.01, 0.05, 0.1, 0.5, 1, 2, 0, 0.001, 0.005, 0.01,\n",
       "                      0.05, 0.1, 0.5, 1, 2, 0, 0.001, 0.005, 0.01, 0.05, 0.1,\n",
       "                      0.5, 1, 2, 0, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 2,\n",
       "                      0, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 2, 0, 0.001,\n",
       "                      0.005, 0.01, 0.05, 0.1, 0.5, 1, 2, 0, 0.001, 0.005,\n",
       "                      0.01, 0.05, 0.1, 0.5, 1, 2],\n",
       "                mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                       True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                       True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                       True,  True,  True,  True,  True,  True,  True,  True,\n",
       "                       True, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False, False, False, False, False,\n",
       "                      False, False, False, False],\n",
       "          fill_value='?',\n",
       "               dtype=object),\n",
       "   'params': [{'C': 1e-07, 'kernel': 'linear'},\n",
       "    {'C': 1e-06, 'kernel': 'linear'},\n",
       "    {'C': 1e-05, 'kernel': 'linear'},\n",
       "    {'C': 0.0001, 'kernel': 'linear'},\n",
       "    {'C': 0.001, 'kernel': 'linear'},\n",
       "    {'C': 0.01, 'kernel': 'linear'},\n",
       "    {'C': 0.1, 'kernel': 'linear'},\n",
       "    {'C': 1.0, 'kernel': 'linear'},\n",
       "    {'C': 10.0, 'kernel': 'linear'},\n",
       "    {'C': 100.0, 'kernel': 'linear'},\n",
       "    {'C': 1000.0, 'kernel': 'linear'},\n",
       "    {'C': 1e-07, 'degree': 2, 'kernel': 'poly'},\n",
       "    {'C': 1e-07, 'degree': 3, 'kernel': 'poly'},\n",
       "    {'C': 1e-06, 'degree': 2, 'kernel': 'poly'},\n",
       "    {'C': 1e-06, 'degree': 3, 'kernel': 'poly'},\n",
       "    {'C': 1e-05, 'degree': 2, 'kernel': 'poly'},\n",
       "    {'C': 1e-05, 'degree': 3, 'kernel': 'poly'},\n",
       "    {'C': 0.0001, 'degree': 2, 'kernel': 'poly'},\n",
       "    {'C': 0.0001, 'degree': 3, 'kernel': 'poly'},\n",
       "    {'C': 0.001, 'degree': 2, 'kernel': 'poly'},\n",
       "    {'C': 0.001, 'degree': 3, 'kernel': 'poly'},\n",
       "    {'C': 0.01, 'degree': 2, 'kernel': 'poly'},\n",
       "    {'C': 0.01, 'degree': 3, 'kernel': 'poly'},\n",
       "    {'C': 0.1, 'degree': 2, 'kernel': 'poly'},\n",
       "    {'C': 0.1, 'degree': 3, 'kernel': 'poly'},\n",
       "    {'C': 1.0, 'degree': 2, 'kernel': 'poly'},\n",
       "    {'C': 1.0, 'degree': 3, 'kernel': 'poly'},\n",
       "    {'C': 10.0, 'degree': 2, 'kernel': 'poly'},\n",
       "    {'C': 10.0, 'degree': 3, 'kernel': 'poly'},\n",
       "    {'C': 100.0, 'degree': 2, 'kernel': 'poly'},\n",
       "    {'C': 100.0, 'degree': 3, 'kernel': 'poly'},\n",
       "    {'C': 1000.0, 'degree': 2, 'kernel': 'poly'},\n",
       "    {'C': 1000.0, 'degree': 3, 'kernel': 'poly'},\n",
       "    {'C': 1e-07, 'gamma': 0, 'kernel': 'rbf'},\n",
       "    {'C': 1e-07, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "    {'C': 1e-07, 'gamma': 0.005, 'kernel': 'rbf'},\n",
       "    {'C': 1e-07, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "    {'C': 1e-07, 'gamma': 0.05, 'kernel': 'rbf'},\n",
       "    {'C': 1e-07, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "    {'C': 1e-07, 'gamma': 0.5, 'kernel': 'rbf'},\n",
       "    {'C': 1e-07, 'gamma': 1, 'kernel': 'rbf'},\n",
       "    {'C': 1e-07, 'gamma': 2, 'kernel': 'rbf'},\n",
       "    {'C': 1e-06, 'gamma': 0, 'kernel': 'rbf'},\n",
       "    {'C': 1e-06, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "    {'C': 1e-06, 'gamma': 0.005, 'kernel': 'rbf'},\n",
       "    {'C': 1e-06, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "    {'C': 1e-06, 'gamma': 0.05, 'kernel': 'rbf'},\n",
       "    {'C': 1e-06, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "    {'C': 1e-06, 'gamma': 0.5, 'kernel': 'rbf'},\n",
       "    {'C': 1e-06, 'gamma': 1, 'kernel': 'rbf'},\n",
       "    {'C': 1e-06, 'gamma': 2, 'kernel': 'rbf'},\n",
       "    {'C': 1e-05, 'gamma': 0, 'kernel': 'rbf'},\n",
       "    {'C': 1e-05, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "    {'C': 1e-05, 'gamma': 0.005, 'kernel': 'rbf'},\n",
       "    {'C': 1e-05, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "    {'C': 1e-05, 'gamma': 0.05, 'kernel': 'rbf'},\n",
       "    {'C': 1e-05, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "    {'C': 1e-05, 'gamma': 0.5, 'kernel': 'rbf'},\n",
       "    {'C': 1e-05, 'gamma': 1, 'kernel': 'rbf'},\n",
       "    {'C': 1e-05, 'gamma': 2, 'kernel': 'rbf'},\n",
       "    {'C': 0.0001, 'gamma': 0, 'kernel': 'rbf'},\n",
       "    {'C': 0.0001, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "    {'C': 0.0001, 'gamma': 0.005, 'kernel': 'rbf'},\n",
       "    {'C': 0.0001, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "    {'C': 0.0001, 'gamma': 0.05, 'kernel': 'rbf'},\n",
       "    {'C': 0.0001, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "    {'C': 0.0001, 'gamma': 0.5, 'kernel': 'rbf'},\n",
       "    {'C': 0.0001, 'gamma': 1, 'kernel': 'rbf'},\n",
       "    {'C': 0.0001, 'gamma': 2, 'kernel': 'rbf'},\n",
       "    {'C': 0.001, 'gamma': 0, 'kernel': 'rbf'},\n",
       "    {'C': 0.001, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "    {'C': 0.001, 'gamma': 0.005, 'kernel': 'rbf'},\n",
       "    {'C': 0.001, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "    {'C': 0.001, 'gamma': 0.05, 'kernel': 'rbf'},\n",
       "    {'C': 0.001, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "    {'C': 0.001, 'gamma': 0.5, 'kernel': 'rbf'},\n",
       "    {'C': 0.001, 'gamma': 1, 'kernel': 'rbf'},\n",
       "    {'C': 0.001, 'gamma': 2, 'kernel': 'rbf'},\n",
       "    {'C': 0.01, 'gamma': 0, 'kernel': 'rbf'},\n",
       "    {'C': 0.01, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "    {'C': 0.01, 'gamma': 0.005, 'kernel': 'rbf'},\n",
       "    {'C': 0.01, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "    {'C': 0.01, 'gamma': 0.05, 'kernel': 'rbf'},\n",
       "    {'C': 0.01, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "    {'C': 0.01, 'gamma': 0.5, 'kernel': 'rbf'},\n",
       "    {'C': 0.01, 'gamma': 1, 'kernel': 'rbf'},\n",
       "    {'C': 0.01, 'gamma': 2, 'kernel': 'rbf'},\n",
       "    {'C': 0.1, 'gamma': 0, 'kernel': 'rbf'},\n",
       "    {'C': 0.1, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "    {'C': 0.1, 'gamma': 0.005, 'kernel': 'rbf'},\n",
       "    {'C': 0.1, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "    {'C': 0.1, 'gamma': 0.05, 'kernel': 'rbf'},\n",
       "    {'C': 0.1, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "    {'C': 0.1, 'gamma': 0.5, 'kernel': 'rbf'},\n",
       "    {'C': 0.1, 'gamma': 1, 'kernel': 'rbf'},\n",
       "    {'C': 0.1, 'gamma': 2, 'kernel': 'rbf'},\n",
       "    {'C': 1.0, 'gamma': 0, 'kernel': 'rbf'},\n",
       "    {'C': 1.0, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "    {'C': 1.0, 'gamma': 0.005, 'kernel': 'rbf'},\n",
       "    {'C': 1.0, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "    {'C': 1.0, 'gamma': 0.05, 'kernel': 'rbf'},\n",
       "    {'C': 1.0, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "    {'C': 1.0, 'gamma': 0.5, 'kernel': 'rbf'},\n",
       "    {'C': 1.0, 'gamma': 1, 'kernel': 'rbf'},\n",
       "    {'C': 1.0, 'gamma': 2, 'kernel': 'rbf'},\n",
       "    {'C': 10.0, 'gamma': 0, 'kernel': 'rbf'},\n",
       "    {'C': 10.0, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "    {'C': 10.0, 'gamma': 0.005, 'kernel': 'rbf'},\n",
       "    {'C': 10.0, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "    {'C': 10.0, 'gamma': 0.05, 'kernel': 'rbf'},\n",
       "    {'C': 10.0, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "    {'C': 10.0, 'gamma': 0.5, 'kernel': 'rbf'},\n",
       "    {'C': 10.0, 'gamma': 1, 'kernel': 'rbf'},\n",
       "    {'C': 10.0, 'gamma': 2, 'kernel': 'rbf'},\n",
       "    {'C': 100.0, 'gamma': 0, 'kernel': 'rbf'},\n",
       "    {'C': 100.0, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "    {'C': 100.0, 'gamma': 0.005, 'kernel': 'rbf'},\n",
       "    {'C': 100.0, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "    {'C': 100.0, 'gamma': 0.05, 'kernel': 'rbf'},\n",
       "    {'C': 100.0, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "    {'C': 100.0, 'gamma': 0.5, 'kernel': 'rbf'},\n",
       "    {'C': 100.0, 'gamma': 1, 'kernel': 'rbf'},\n",
       "    {'C': 100.0, 'gamma': 2, 'kernel': 'rbf'},\n",
       "    {'C': 1000.0, 'gamma': 0, 'kernel': 'rbf'},\n",
       "    {'C': 1000.0, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "    {'C': 1000.0, 'gamma': 0.005, 'kernel': 'rbf'},\n",
       "    {'C': 1000.0, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "    {'C': 1000.0, 'gamma': 0.05, 'kernel': 'rbf'},\n",
       "    {'C': 1000.0, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "    {'C': 1000.0, 'gamma': 0.5, 'kernel': 'rbf'},\n",
       "    {'C': 1000.0, 'gamma': 1, 'kernel': 'rbf'},\n",
       "    {'C': 1000.0, 'gamma': 2, 'kernel': 'rbf'}],\n",
       "   'split0_test_score': array([0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505,\n",
       "          0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505,\n",
       "          0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505,\n",
       "          0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505,\n",
       "          0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505,\n",
       "          0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505,\n",
       "          0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505,\n",
       "          0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505,\n",
       "          0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505,\n",
       "          0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505,\n",
       "          0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505,\n",
       "          0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505,\n",
       "          0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505,\n",
       "          0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505,\n",
       "          0.505, 0.505, 0.505, 0.505, 0.505, 0.505]),\n",
       "   'split1_test_score': array([0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.506, 0.506,\n",
       "          0.506, 0.506, 0.505, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506,\n",
       "          0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506,\n",
       "          0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.505, 0.505, 0.505,\n",
       "          0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505,\n",
       "          0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505,\n",
       "          0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505,\n",
       "          0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505,\n",
       "          0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505,\n",
       "          0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505,\n",
       "          0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505,\n",
       "          0.505, 0.505, 0.505, 0.506, 0.506, 0.506, 0.505, 0.505, 0.505,\n",
       "          0.505, 0.506, 0.506, 0.506, 0.506, 0.506, 0.505, 0.505, 0.506,\n",
       "          0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.505, 0.506, 0.506,\n",
       "          0.506, 0.506, 0.506, 0.506, 0.506, 0.506]),\n",
       "   'split2_test_score': array([0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505,\n",
       "          0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505,\n",
       "          0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505,\n",
       "          0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505,\n",
       "          0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505,\n",
       "          0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505,\n",
       "          0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505,\n",
       "          0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505,\n",
       "          0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505,\n",
       "          0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505,\n",
       "          0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505,\n",
       "          0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505,\n",
       "          0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505,\n",
       "          0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505, 0.505,\n",
       "          0.505, 0.505, 0.505, 0.505, 0.505, 0.505]),\n",
       "   'split3_test_score': array([0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506,\n",
       "          0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506,\n",
       "          0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506,\n",
       "          0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506,\n",
       "          0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506,\n",
       "          0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506,\n",
       "          0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506,\n",
       "          0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506,\n",
       "          0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506,\n",
       "          0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506,\n",
       "          0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506,\n",
       "          0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506,\n",
       "          0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506,\n",
       "          0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506,\n",
       "          0.506, 0.506, 0.506, 0.506, 0.506, 0.506]),\n",
       "   'split4_test_score': array([0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.508, 0.508,\n",
       "          0.508, 0.508, 0.506, 0.508, 0.508, 0.508, 0.508, 0.508, 0.508,\n",
       "          0.508, 0.508, 0.508, 0.508, 0.508, 0.508, 0.508, 0.508, 0.508,\n",
       "          0.508, 0.508, 0.508, 0.508, 0.508, 0.508, 0.506, 0.506, 0.506,\n",
       "          0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506,\n",
       "          0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506,\n",
       "          0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506,\n",
       "          0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506,\n",
       "          0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506,\n",
       "          0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506,\n",
       "          0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506, 0.506,\n",
       "          0.506, 0.506, 0.506, 0.506, 0.508, 0.508, 0.506, 0.506, 0.506,\n",
       "          0.506, 0.506, 0.508, 0.508, 0.508, 0.508, 0.506, 0.506, 0.506,\n",
       "          0.508, 0.508, 0.508, 0.508, 0.508, 0.508, 0.506, 0.508, 0.508,\n",
       "          0.508, 0.508, 0.508, 0.508, 0.508, 0.508]),\n",
       "   'mean_test_score': array([0.5054, 0.5054, 0.5054, 0.5054, 0.5054, 0.5054, 0.5054, 0.506 ,\n",
       "          0.506 , 0.506 , 0.506 , 0.5054, 0.506 , 0.506 , 0.506 , 0.506 ,\n",
       "          0.506 , 0.506 , 0.506 , 0.506 , 0.506 , 0.506 , 0.506 , 0.506 ,\n",
       "          0.506 , 0.506 , 0.506 , 0.506 , 0.506 , 0.506 , 0.506 , 0.506 ,\n",
       "          0.506 , 0.5054, 0.5054, 0.5054, 0.5054, 0.5054, 0.5054, 0.5054,\n",
       "          0.5054, 0.5054, 0.5054, 0.5054, 0.5054, 0.5054, 0.5054, 0.5054,\n",
       "          0.5054, 0.5054, 0.5054, 0.5054, 0.5054, 0.5054, 0.5054, 0.5054,\n",
       "          0.5054, 0.5054, 0.5054, 0.5054, 0.5054, 0.5054, 0.5054, 0.5054,\n",
       "          0.5054, 0.5054, 0.5054, 0.5054, 0.5054, 0.5054, 0.5054, 0.5054,\n",
       "          0.5054, 0.5054, 0.5054, 0.5054, 0.5054, 0.5054, 0.5054, 0.5054,\n",
       "          0.5054, 0.5054, 0.5054, 0.5054, 0.5054, 0.5054, 0.5054, 0.5054,\n",
       "          0.5054, 0.5054, 0.5054, 0.5054, 0.5054, 0.5054, 0.5054, 0.5054,\n",
       "          0.5054, 0.5054, 0.5054, 0.5054, 0.5054, 0.5054, 0.5056, 0.506 ,\n",
       "          0.506 , 0.5054, 0.5054, 0.5054, 0.5054, 0.5056, 0.506 , 0.506 ,\n",
       "          0.506 , 0.506 , 0.5054, 0.5054, 0.5056, 0.506 , 0.506 , 0.506 ,\n",
       "          0.506 , 0.506 , 0.506 , 0.5054, 0.506 , 0.506 , 0.506 , 0.506 ,\n",
       "          0.506 , 0.506 , 0.506 , 0.506 ]),\n",
       "   'std_test_score': array([0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "          0.0004899 , 0.0004899 , 0.00109545, 0.00109545, 0.00109545,\n",
       "          0.00109545, 0.0004899 , 0.00109545, 0.00109545, 0.00109545,\n",
       "          0.00109545, 0.00109545, 0.00109545, 0.00109545, 0.00109545,\n",
       "          0.00109545, 0.00109545, 0.00109545, 0.00109545, 0.00109545,\n",
       "          0.00109545, 0.00109545, 0.00109545, 0.00109545, 0.00109545,\n",
       "          0.00109545, 0.00109545, 0.00109545, 0.0004899 , 0.0004899 ,\n",
       "          0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "          0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "          0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "          0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "          0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "          0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "          0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "          0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "          0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "          0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "          0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "          0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "          0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "          0.0004899 , 0.0004899 , 0.0004899 , 0.00109545, 0.00109545,\n",
       "          0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 , 0.0004899 ,\n",
       "          0.00109545, 0.00109545, 0.00109545, 0.00109545, 0.0004899 ,\n",
       "          0.0004899 , 0.0004899 , 0.00109545, 0.00109545, 0.00109545,\n",
       "          0.00109545, 0.00109545, 0.00109545, 0.0004899 , 0.00109545,\n",
       "          0.00109545, 0.00109545, 0.00109545, 0.00109545, 0.00109545,\n",
       "          0.00109545, 0.00109545]),\n",
       "   'rank_test_score': array([49, 49, 49, 49, 49, 49, 49,  1,  1,  1,  1, 49,  1,  1,  1,  1,  1,\n",
       "           1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 49,\n",
       "          49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49,\n",
       "          49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49,\n",
       "          49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49,\n",
       "          49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49,\n",
       "          46,  1,  1, 49, 49, 49, 49, 46,  1,  1,  1,  1, 49, 49, 46,  1,  1,\n",
       "           1,  1,  1,  1, 49,  1,  1,  1,  1,  1,  1,  1,  1], dtype=int32)}}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = load_dict('../checkpoints/svm/svm_clickbait_0.pickle')\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
