{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Misc\n",
    "import json # saving/loading metrics\n",
    "\n",
    "# ML\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dict(dictionary, filename, verbose=False):\n",
    "    '''\n",
    "    Saves dictionary object as json file for reloading and easy viewing\n",
    "    \n",
    "    Args:\n",
    "    - dictionary (dict): data to be saved\n",
    "    - filename (str): filename for dictionary to be stored in\n",
    "    - verbose=False (bool): sepcifies if exact filename should be used. if False, .json extension appended to filename if not already present\n",
    "    Return:\n",
    "    - filename (str): filename for dictionary to be stored in\n",
    "    '''\n",
    "    if (not verbose) and ('.json' not in filename):\n",
    "        filename += '.json'\n",
    "        \n",
    "    with open(filename, \"w\") as outfile:  \n",
    "        json.dump(dictionary, outfile) \n",
    "    \n",
    "    return filename\n",
    "        \n",
    "def load_dict(filename, verbose=False):\n",
    "    '''\n",
    "    Loads dictionaary of metrics from given filename\n",
    "    \n",
    "    Args:\n",
    "    - filename (str): file to load\n",
    "    - verbose=False (bool): sepcifies if exact filename should be used. if False, .json extension appended to filename if not already present\n",
    "    Return\n",
    "    - dictionary (dict): data found in file\n",
    "    - None (None): return None val in case exception is raised and dictionary file does not exist\n",
    "    '''\n",
    "    if (not verbose) and ('.json' not in filename):\n",
    "        filename += '.json'\n",
    "\n",
    "    try:\n",
    "        with open(filename) as json_file: \n",
    "            dictionary = json.load(json_file) \n",
    "    except FileNotFoundError as e:\n",
    "        print(e)\n",
    "        return None\n",
    "    \n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import letter recognition data, transform label, and convert to array\n",
    "POSITIVE_LETTERS = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M']\n",
    "\n",
    "letter_df = pd.read_csv('../data/letter-recognition.data', names=np.arange(1,18))\n",
    "letter_df[1] = letter_df[1].apply(lambda letter: 1 if letter in POSITIVE_LETTERS else -1)\n",
    "letter_data = letter_df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create metric dict\n",
    "svm_metric_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid\n",
    "c_vals = [1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3]\n",
    "param_grid = [{'kernel': ['linear'], 'C': c_vals}, {'kernel': ['poly'], 'degree': [0,2,3], 'C': c_vals}, {'kernel': ['rbf'], 'gamma': [0, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 2], 'C': c_vals}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model & grid search object\n",
    "svc = SVC()\n",
    "clf_svc = GridSearchCV(estimator=svc, param_grid=param_grid, cv=5, n_jobs=2, verbose=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in [letter_data]:\n",
    "    # Get data\n",
    "    X, y = dataset[:, 1:], dataset[:, :1] #Treats first column as label\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=5000, shuffle=True)\n",
    "    for i in range(3):\n",
    "        clf_svc.fit(X_train, y_train.ravel()) # Fit training data to model\n",
    "        y_test_pred = clf_svc.predict(X_test) # Predict test values using best parameters from classifier\n",
    "        acc = accuracy_score(y_test, y_test_pred) # Get accuracy for predictions\n",
    "        svm_metric_dict[(dataset, i)] = {'cv_results': clf_svc.cv_results_, 'acc': acc} # Add metrics to dict for analysis\n",
    "        save_dict(svm_metric_dict, '../checkpoints/svm/svm_{}_{}.json'.format(dataset, i)) # Save checkpoint results in case of hardware failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "###### DEPRACATED FOR MULTITHREAD SKLEARN GRID SEARCH, KEPT IN CASE OF MEASURING OTHER METRICS\n",
    "from sklearn.model_selection import KFold, ParameterGrid\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Cycle across each param combo\n",
    "performance_dict = {}\n",
    "for param_dict in tqdm(list(ParameterGrid(param_grid))):\n",
    "    performance = 0\n",
    "    C, degree, gamma, kernel = param_dict.values()\n",
    "    if ((kernel in ('linear', 'rbf') and degree > 0) or  # Don't want to run linear or rbf with polynomial degrees (degree will be ignored but we'll get duplicate trials)\n",
    "        (kernel == 'poly' and degree == 0) or # Don't want polynomial with degree 0\n",
    "        (kernel in ('linear', 'poly') and gamma > 0) or # Don't want linear or poly with gamma param\n",
    "        (kernel == 'rbf' and gamma == 0)): # Don't want rbf with 0 gamma\n",
    "        continue\n",
    "    # Do k fold validation\n",
    "    for train, validate in kf.split(X_letter_train):\n",
    "        X_letter_train_cross, X_letter_val_cross, y_letter_train_cross, y_letter_val_cross = X_letter_train[train], X_letter_train[validate], y_letter_train[train], y_letter_train[validate] # get data folds\n",
    "        svm_letter = SVC(C=C, degree=degree, kernel=kernel) # create the model #NOTE: not scaling because all data appears to follow the same scaling regardless\n",
    "        svm_letter.fit(X_letter_train_cross, y_letter_train_cross.ravel()) # fit the model\n",
    "        y_letter_val_cross_pred = svm_letter.predict(X_letter_val_cross) # predict validation data\n",
    "        performance += accuracy_score(y_letter_val_cross, y_letter_val_cross_pred) # keep track of performance\n",
    "    # Average the performance\n",
    "    performance /= 5\n",
    "    \n",
    "    # Add performance info to dict\n",
    "    performance_dict[(C, degree, kernel)] = performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
